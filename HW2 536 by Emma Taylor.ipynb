{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd313c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Homework 2 for EconS 536 by Emma Taylor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23719224",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1\n",
    "\n",
    "### 1. True. As long as the multicollinearity is not perfect,\n",
    "### Bhat will still exist and be BLUE. Bhat is highly unstable,\n",
    "### but Bhat still passes the BLUE procedure such that E[Bhat] = B\n",
    "### and the Gauss-Markov Theorem proves that Bhat has the smallest\n",
    "### relative variance. The variance may be quite large, but \n",
    "### in relative terms to other estimators, it is still the smallest.\n",
    "\n",
    "### 2. False. This model has a quadratic term for age, so the marginal\n",
    "### effect of age will change over the model and will not be equal to\n",
    "### the simple regression coefficient. The d coefficient implies that\n",
    "### holding all else constant, women's incomes are $4,000 higher than\n",
    "### men's (this would be a parallel shift upwards of the regression line).\n",
    "### However, in practice, this would be a very poorly specified model of\n",
    "### income, so this effect is not likely to exist in the real world.\n",
    "\n",
    "### 3. True. The likelihood ratio test compares the log likelihood\n",
    "### of a restricted model with an unrestricted model, therefore\n",
    "### producing a test statistic describing the relative usefulness of\n",
    "### the two models. The Wald test reaches the same test statistic in\n",
    "### large samples, so these two tests are asymptotically equivalent.\n",
    "### Though the LM test is only carried out with the restricted model,\n",
    "### it will always reach the same conclusion as the Wald and LR tests\n",
    "### in large samples, therefore, these three test are asymptotically\n",
    "### equivalent, and the additional two tests are redundant.\n",
    "\n",
    "### 4. False. The OLS estimator for the covariance matrix of B is\n",
    "### sigma2*(X'X)^-1, and under heteroskedasticity, the estimator \n",
    "### will be the sandwich form estimator with an additional parameter\n",
    "### omega multiplied by sigma^2. So, Bhat = (X'X)^-1X'Y definitely\n",
    "### cannot be an unbiased and consistent estimator of the covariance\n",
    "### matrix of B. However, it is the case that Bhat will remain an\n",
    "### unbiased and consistent estimator of B itself under hetero-\n",
    "### skedasticity. (It will not be an efficient estimator.)\n",
    "\n",
    "### 5. False. As referenced in question 4, heteroskedasticity\n",
    "### transforms the estimation of the covariance matrix into the\n",
    "### sandwhich form with an additional parameter omega within\n",
    "### the estimator. This means that the variance estimator will\n",
    "### be biased, and so the resulting standard errors and test\n",
    "### statistics in this model will be invalid. Heteroskedasticity\n",
    "### creates an issue in the second moment, so our variance\n",
    "### estimators will certainly be biased and inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7811c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     QMaize  Qrice  Qbeef  Qfish  Pmaize  Price  Pbeef  Pfish  Expenditure\n",
      "0      4.17   1.74   1.56   2.33     120    230    320    300       2098.8\n",
      "1     15.00   4.18   0.57   2.76     100    220    350    380       3667.9\n",
      "2     10.00   0.68   1.14   1.84     100    220    350    380       2247.8\n",
      "3      8.33   1.91   0.31   1.25     120    230    320    300       1913.1\n",
      "4      1.20   2.05   0.86   0.92     100    220    350    380       1221.6\n",
      "..      ...    ...    ...    ...     ...    ...    ...    ...          ...\n",
      "120   12.00   9.09   0.57   2.76     100    220    350    380       4448.1\n",
      "121    3.89   6.46   8.00   3.75      90    260    350    160       5429.7\n",
      "122    5.60   3.16   5.00   4.21     100    190    360    190       3760.3\n",
      "123    7.50   1.60   1.00   1.54     200    250    400    390       2900.6\n",
      "124   12.50   4.35   1.67   4.00      40    230    150    250       2751.0\n",
      "\n",
      "[125 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "### Part 2\n",
    "\n",
    "### packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "### import data\n",
    "df = pd.read_excel(r'C:\\Users\\emmat\\Downloads\\HW2 2022.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72afd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_summary:\n",
      "           QMaize       Qrice       Qbeef       Qfish      Pmaize       Price  \\\n",
      "count  125.000000  125.000000  125.000000  125.000000  125.000000  125.000000   \n",
      "mean     8.489520    4.569680    2.650000    3.371600  120.880000  220.240000   \n",
      "std      5.896875    3.510744    2.187694    2.559905   47.247051   19.856907   \n",
      "min      1.000000    0.400000    0.140000    0.080000   40.000000  150.000000   \n",
      "25%      4.400000    2.050000    1.110000    1.580000  100.000000  220.000000   \n",
      "50%      7.000000    3.480000    1.810000    2.630000  100.000000  220.000000   \n",
      "75%     10.910000    5.910000    3.140000    4.740000  120.000000  230.000000   \n",
      "max     30.000000   17.390000   10.670000   15.790000  250.000000  260.000000   \n",
      "\n",
      "            Pbeef       Pfish   Expenditure  \n",
      "count  125.000000  125.000000    125.000000  \n",
      "mean   342.160000  335.200000   3918.020000  \n",
      "std     29.827028   75.472704   2004.523523  \n",
      "min    150.000000  160.000000    801.900000  \n",
      "25%    350.000000  280.000000   2439.700000  \n",
      "50%    350.000000  380.000000   3651.400000  \n",
      "75%    350.000000  380.000000   4801.600000  \n",
      "max    400.000000  420.000000  12499.100000  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### a. descriptive statistics\n",
    "Data_summary = df.describe()\n",
    "print(f'Data_summary:\\n{Data_summary}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc06a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Qbeef   R-squared:                       0.350\n",
      "Model:                            OLS   Adj. R-squared:                  0.339\n",
      "Method:                 Least Squares   F-statistic:                     32.85\n",
      "Date:                Fri, 25 Feb 2022   Prob (F-statistic):           3.87e-12\n",
      "Time:                        08:19:15   Log-Likelihood:                -247.80\n",
      "No. Observations:                 125   AIC:                             501.6\n",
      "Df Residuals:                     122   BIC:                             510.1\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       1.6141      1.852      0.872      0.385      -2.051       5.279\n",
      "Pbeef          -0.0044      0.005     -0.815      0.417      -0.015       0.006\n",
      "Expenditure     0.0006   7.98e-05      8.095      0.000       0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                       21.396   Durbin-Watson:                   2.071\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.181\n",
      "Skew:                           0.929   Prob(JB):                     7.59e-07\n",
      "Kurtosis:                       4.400   Cond. No.                     5.13e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.13e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### b. linear regression\n",
    "\n",
    "### GLM where Y = Qbeef, X=[1, Pbeef, Expenditure]' + e\n",
    "reg = smf.ols(formula='Qbeef ~ Pbeef + Expenditure', data=df)\n",
    "results = reg.fit()\n",
    "print (f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "### interpretation:\n",
    "### This model does not seem to be a great model for understanding\n",
    "### the demand for beef. Price of beef is not even close to being\n",
    "### a significant predictor, and the intercept is also statistically\n",
    "### insignificant. Both price of beef and the intercept are essentially\n",
    "### equivalent to 0. \n",
    "### However, the expenditure variable is statistically significant.\n",
    "### For each additional unit of expenditure (assuming dollars?),\n",
    "### quantity of beef demanded will increase by 0.0006 units (maybe tons?),\n",
    "### all else held constant. \n",
    "### The adjusted R-squared of this model is 0.339, which means that \n",
    "### 33.9% of the variation in quantity of beef demanded is explained by\n",
    "### this model. Most, if not all, of that variation is being explained\n",
    "### by the expenditure variable. \n",
    "### If this model were cross-sectional, .339 would be a strong adjusted\n",
    "### R-squared value. Though I do not know for sure, it seems to me that\n",
    "### this is time series data (possibly 10 years of monthly data).\n",
    "### For time series data, this is a fairly weak adj. R-squared.\n",
    "### This checks out when compared to the lack of significance of\n",
    "### the price variable and intercept variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce205a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fstat1: 32.84588825145803\n",
      "\n",
      "fpval1: 3.870701942500826e-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### c. f test\n",
    "\n",
    "### setting the hypothesis for the ftest\n",
    "hypotheses1 = ['Pbeef = Expenditure = 0']\n",
    "ftest = results.f_test(hypotheses1)\n",
    "\n",
    "### test statistics\n",
    "fstat = ftest.statistic[0][0]\n",
    "fpval = ftest.pvalue\n",
    "print(f'fstat1: {fstat}\\n')\n",
    "print(f'fpval1: {fpval}\\n')\n",
    "\n",
    "### The critical value for this F-test is ~3, which 32.8 far exceeds,\n",
    "### so we can reject the null hypothesis and say that at least one\n",
    "### variable in this model is not equal to 0; it is statistically\n",
    "### significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### d. marginal effects\n",
    "\n",
    "### In this case of simple linear regression, the marginal effects\n",
    "### of each variable are equal to the regression coefficients.\n",
    "### Therefore, the marginal effect of the price of beef is -0.0044.\n",
    "### This means that an increase in price of beef by one unit will\n",
    "### decrease quantity demanded by -0.0044, all other variables\n",
    "### held constant. Of course, this variable is not statistically\n",
    "### significant, so truly it is equal to 0 and change in price \n",
    "### of beef will not change quantity demanded.\n",
    "### The marginal effect of expenditue is equal to 0.0006,\n",
    "### meaning that a one unit increase in expenditure will increase\n",
    "### quantity demanded by 0.0006 units, ceteris paribus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19e9a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticity_summary:\n",
      "       Price Elasticity  Income Elasticity\n",
      "count         34.000000         124.000000\n",
      "mean          -6.372583           7.359883\n",
      "std           22.359644          69.202599\n",
      "min          -87.137931        -224.216471\n",
      "25%           -8.412296           0.000000\n",
      "50%           -2.085818           1.162805\n",
      "75%            3.041115           2.962615\n",
      "max           34.925373         703.713142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### e. elasticities at every point\n",
    "\n",
    "### calculates % change between an observation and its immediate predecessor\n",
    "df[\"% Change in Quantity\"] = df[\"Qbeef\"].pct_change()\n",
    "df[\"% Change in Price\"] = df[\"Pbeef\"].pct_change()\n",
    "df[\"% Change in Income\"] = df[\"Expenditure\"].pct_change()\n",
    "\n",
    "### creating new elasticity columns\n",
    "df[\"Price Elasticity\"] = df[\"% Change in Quantity\"] / df[\"% Change in Price\"]\n",
    "df[\"Income Elasticity\"] = df[\"% Change in Quantity\"] / df[\"% Change in Income\"]\n",
    "\n",
    "### where price did not change between observations, our percent change = 0,\n",
    "### meaning an elasticity cannot be calculated at this point\n",
    "### this process drops those observations so that summary stats can\n",
    "### be calculated\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna()\n",
    "\n",
    "### subsetting the elasticities for summary stats\n",
    "df_elasticity = df[['Price Elasticity','Income Elasticity']]\n",
    "\n",
    "### elasticity summary stats\n",
    "elasticity_summary = df_elasticity.describe()\n",
    "print(f'elasticity_summary:\\n{elasticity_summary}\\n')\n",
    "\n",
    "### interpretation:\n",
    "### The mean of the price elasticities is equal to -6.37, which implies that\n",
    "### for a 10% reduction in price, quantity demanded for beef will increase\n",
    "### by 63.7%. This is highly elastic demand. This seems somewhat unrealistic,\n",
    "### based on our previous conversation in class about beef demand.\n",
    "### The mean of the income elasticities is equal to 7.36, implying that\n",
    "### for a 10% increase in income (expenditure), quantity of beef demanded\n",
    "### should increase by 73.6%. This is highly elastic, and again somewhat\n",
    "### unrealistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d02f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "### f. mean elasticity\n",
    "\n",
    "### arc price elasticity of demand\n",
    "### PED = ( (0.14 − 10.67) / (0.14 + 10.67) / 2) / ( (400 - 350) / (400 + 350) / 2)\n",
    "### = -14.6115\n",
    "\n",
    "### arc income elasticity\n",
    "### IED = ( (0.14 − 10.67) / (0.14 + 10.67) / 2) / ( (801 - 12499) / (801 + 12499) / 2)\n",
    "### = 1.1075\n",
    "\n",
    "### As with part e, both price elasticity and income elasticity are elastic.\n",
    "### However, PED is now twice as elastic using this method, meaning that for\n",
    "### a ten percent decrease in the price of beef, quantity demanded will increase\n",
    "### by 140%. \n",
    "### Income elasticity of demand is actually of a reasonable level with this\n",
    "### method. For a 10% increase in income, quantity of beef demanded would be\n",
    "### 11% higher. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
